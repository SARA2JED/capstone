{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "song_data = pd.read_csv(\"clean_file.csv\")\n",
    "df = pd.DataFrame(song_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data = pd.read_csv(\"clean_file.csv\")\n",
    "df = pd.DataFrame(song_data)\n",
    "\n",
    "file = open(\"testhappy.txt\")\n",
    "line = file.read().replace(\"\\n\", \" \")\n",
    "file.close()\n",
    "\n",
    "doc_1 = df['processed_text'].iloc[4]\n",
    "doc_2 = line\n",
    "\n",
    "data = [doc_1 ,doc_2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "',processed_text 12,you look away me western sky call you color spill run dazzl i way voic east saw root tree plant foot it could im search place small room everyth world revolv but wait hold back suppos clever one word came easi say write song mayb vers yet tobe found insid secret tangl web unweav know on still late 24,you 118,the paint desert till summer weve play game imagin long enough when sure rain end bloom gone everyon kill morn frost is cactu everi roadsid stand big deal cowboy gear japan the upon northern rim ruin hopi mesa den met new friend canyon wrote blanket cool sand agre that star mani seem overlap wa watch nativ boy in flagstaff trailer court line he kick tumblewe mother home arizona moon sun want may latest time isnt plan chang mind read sinc phoenix tucson april tell there 131,id like make stay eye escap think feel cold confess unfold youll never live get direct exit sign heart find hide u matter expo fall reveal all stuck knee and le push forward ambit breez flame must fan appear beckon hand dont caus talk kind 195,desper frozen core numb to need someth keep be hope for someon take befor go promis leav lifeless will bow life freedom lose where move so slow again knew 339,thing tire alway pretend come well brought lie believ them let enjoy ride what light wanna side night some peopl pay thing got much show they theyr stronger now longer ive spent whole day last see ooh 367,all mix up music hexum lyric hexummartinez youv trust instinct regret bet best wick wild said we funki style known hip hop regga fuck naysay mean bring chest shine dream mine do next turn around person thought freak might first as pas sick bit bustin session quit cant fact even fulli legit gal thatl dem stun nervou throat dri my brain empti whi which realli truli noth bust tri save skate fine 373,all 551,no guess gotta choru spend if requir then ill hurri bu just hang phone alreadi own dig were togeth act money doubl becaus yyour happi out love pawn shop babi a wed ring boom box oww el good anyway id forev yo 599,you stumbl carri fear set instant too thi weakest scare truth tend goe wrong sad alon no oh done who care listen gonna respect wake doubt left lead reserv right uncomfort afraid mistak humbl step better master cast stone judgement am x god help themselv forget lost nerv miss point open burden yeah close distanc 651,they notic yearsbut same past puddl rememb stain slip ledg chosen final pick role part tragedi from breaksmi break 653,life lesson learn hard four random white unmark van park outsid hotel high rise garag use iron bone leg bad wreck heard littl girl today blood face safe target earn disgust 670,you 716,pick sleaz car hell far burn road scold bite these finer paradis filli wrap red decker bed suckin juic bar downin shooter checkin sight blow 745,black sheep renegad hot shade street shuffl tough childhood examin tall hotwir speed veem cheap cigar rebellion ok rule readi top neighborhood case trash societi rash gash real rough your regul tie shoe those fool with bunch 754,pick 824,jingl bell jingl christma grope hay have lot dough low lovem leavem meapho mid glass capit lace date woman heaven three she mistress slippin bodi hear smoke stake reindeer honey 888,there fight march die fright here razor edg breath neck rais dead cut shred 950,cold ice bitter decemb winter treat sometim loo temper cross would near myself along deep without dark obnoxi down'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_1 \n",
    "doc_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x634 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 650 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "vector_matrix = count_vectorizer.fit_transform(data)\n",
    "vector_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pca\\Desktop\\capstone\\.venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['118',\n",
       " '12',\n",
       " '131',\n",
       " '195',\n",
       " '24',\n",
       " '339',\n",
       " '367',\n",
       " '373',\n",
       " '551',\n",
       " '599',\n",
       " '651',\n",
       " '653',\n",
       " '670',\n",
       " '716',\n",
       " '745',\n",
       " '754',\n",
       " '824',\n",
       " '888',\n",
       " '950',\n",
       " 'act',\n",
       " 'afraid',\n",
       " 'again',\n",
       " 'agre',\n",
       " 'all',\n",
       " 'alon',\n",
       " 'along',\n",
       " 'alreadi',\n",
       " 'alway',\n",
       " 'am',\n",
       " 'ambit',\n",
       " 'and',\n",
       " 'anyway',\n",
       " 'appear',\n",
       " 'april',\n",
       " 'arizona',\n",
       " 'armagedon',\n",
       " 'around',\n",
       " 'as',\n",
       " 'away',\n",
       " 'babi',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'bar',\n",
       " 'be',\n",
       " 'becaus',\n",
       " 'beckon',\n",
       " 'bed',\n",
       " 'befor',\n",
       " 'believ',\n",
       " 'bell',\n",
       " 'bench',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'better',\n",
       " 'big',\n",
       " 'bit',\n",
       " 'bite',\n",
       " 'bitter',\n",
       " 'black',\n",
       " 'blanket',\n",
       " 'blood',\n",
       " 'bloom',\n",
       " 'blow',\n",
       " 'bodi',\n",
       " 'bomb',\n",
       " 'bone',\n",
       " 'boom',\n",
       " 'bow',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'brain',\n",
       " 'break',\n",
       " 'breaksmi',\n",
       " 'breath',\n",
       " 'breez',\n",
       " 'bring',\n",
       " 'brought',\n",
       " 'bu',\n",
       " 'bunch',\n",
       " 'burden',\n",
       " 'burn',\n",
       " 'bust',\n",
       " 'bustin',\n",
       " 'but',\n",
       " 'cactu',\n",
       " 'call',\n",
       " 'came',\n",
       " 'cant',\n",
       " 'canyon',\n",
       " 'capit',\n",
       " 'car',\n",
       " 'card',\n",
       " 'care',\n",
       " 'carri',\n",
       " 'case',\n",
       " 'cast',\n",
       " 'caus',\n",
       " 'chang',\n",
       " 'cheap',\n",
       " 'checkin',\n",
       " 'chest',\n",
       " 'childhood',\n",
       " 'choru',\n",
       " 'chosen',\n",
       " 'christma',\n",
       " 'cigar',\n",
       " 'clever',\n",
       " 'close',\n",
       " 'cloth',\n",
       " 'coastal',\n",
       " 'cold',\n",
       " 'color',\n",
       " 'come',\n",
       " 'confess',\n",
       " 'cool',\n",
       " 'core',\n",
       " 'could',\n",
       " 'court',\n",
       " 'cowboy',\n",
       " 'cross',\n",
       " 'cut',\n",
       " 'dark',\n",
       " 'date',\n",
       " 'day',\n",
       " 'dazzl',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'dearli',\n",
       " 'decemb',\n",
       " 'decker',\n",
       " 'deep',\n",
       " 'dem',\n",
       " 'den',\n",
       " 'desert',\n",
       " 'desper',\n",
       " 'die',\n",
       " 'dig',\n",
       " 'direct',\n",
       " 'disgust',\n",
       " 'distanc',\n",
       " 'do',\n",
       " 'done',\n",
       " 'dont',\n",
       " 'doubl',\n",
       " 'doubt',\n",
       " 'dough',\n",
       " 'down',\n",
       " 'downin',\n",
       " 'dream',\n",
       " 'dri',\n",
       " 'dust',\n",
       " 'earn',\n",
       " 'easi',\n",
       " 'east',\n",
       " 'edg',\n",
       " 'el',\n",
       " 'empti',\n",
       " 'end',\n",
       " 'enjoy',\n",
       " 'enough',\n",
       " 'escap',\n",
       " 'etch',\n",
       " 'even',\n",
       " 'everi',\n",
       " 'everyday',\n",
       " 'everyon',\n",
       " 'everyth',\n",
       " 'examin',\n",
       " 'exit',\n",
       " 'expo',\n",
       " 'eye',\n",
       " 'face',\n",
       " 'fact',\n",
       " 'fall',\n",
       " 'fan',\n",
       " 'far',\n",
       " 'fear',\n",
       " 'feel',\n",
       " 'fight',\n",
       " 'filli',\n",
       " 'final',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'finer',\n",
       " 'first',\n",
       " 'flagstaff',\n",
       " 'flame',\n",
       " 'fool',\n",
       " 'foot',\n",
       " 'for',\n",
       " 'forev',\n",
       " 'forget',\n",
       " 'forgot',\n",
       " 'forward',\n",
       " 'found',\n",
       " 'four',\n",
       " 'freak',\n",
       " 'freedom',\n",
       " 'friend',\n",
       " 'fright',\n",
       " 'from',\n",
       " 'frost',\n",
       " 'frozen',\n",
       " 'fuck',\n",
       " 'fulli',\n",
       " 'funki',\n",
       " 'gal',\n",
       " 'game',\n",
       " 'garag',\n",
       " 'gash',\n",
       " 'gear',\n",
       " 'get',\n",
       " 'girl',\n",
       " 'glass',\n",
       " 'go',\n",
       " 'god',\n",
       " 'goe',\n",
       " 'gone',\n",
       " 'gonna',\n",
       " 'good',\n",
       " 'got',\n",
       " 'gotta',\n",
       " 'greas',\n",
       " 'grey',\n",
       " 'grope',\n",
       " 'guess',\n",
       " 'hand',\n",
       " 'hang',\n",
       " 'happi',\n",
       " 'hard',\n",
       " 'have',\n",
       " 'hay',\n",
       " 'he',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'heart',\n",
       " 'heaven',\n",
       " 'hell',\n",
       " 'help',\n",
       " 'here',\n",
       " 'hexum',\n",
       " 'hexummartinez',\n",
       " 'hide',\n",
       " 'high',\n",
       " 'hip',\n",
       " 'hold',\n",
       " 'home',\n",
       " 'honey',\n",
       " 'hop',\n",
       " 'hope',\n",
       " 'hopi',\n",
       " 'hot',\n",
       " 'hotel',\n",
       " 'hotwir',\n",
       " 'how',\n",
       " 'humbl',\n",
       " 'hurri',\n",
       " 'ice',\n",
       " 'id',\n",
       " 'if',\n",
       " 'ill',\n",
       " 'im',\n",
       " 'imagin',\n",
       " 'in',\n",
       " 'insid',\n",
       " 'instant',\n",
       " 'instinct',\n",
       " 'iron',\n",
       " 'is',\n",
       " 'isnt',\n",
       " 'it',\n",
       " 'ive',\n",
       " 'japan',\n",
       " 'jingl',\n",
       " 'judgement',\n",
       " 'juic',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'kick',\n",
       " 'kill',\n",
       " 'kind',\n",
       " 'knee',\n",
       " 'knew',\n",
       " 'know',\n",
       " 'known',\n",
       " 'lace',\n",
       " 'land',\n",
       " 'last',\n",
       " 'late',\n",
       " 'latest',\n",
       " 'le',\n",
       " 'lead',\n",
       " 'learn',\n",
       " 'leav',\n",
       " 'leavem',\n",
       " 'ledg',\n",
       " 'left',\n",
       " 'leg',\n",
       " 'legit',\n",
       " 'lesson',\n",
       " 'let',\n",
       " 'lie',\n",
       " 'life',\n",
       " 'lifeless',\n",
       " 'light',\n",
       " 'like',\n",
       " 'line',\n",
       " 'listen',\n",
       " 'littl',\n",
       " 'live',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'loo',\n",
       " 'look',\n",
       " 'lose',\n",
       " 'lost',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'lovem',\n",
       " 'low',\n",
       " 'lyric',\n",
       " 'make',\n",
       " 'mani',\n",
       " 'march',\n",
       " 'master',\n",
       " 'matter',\n",
       " 'may',\n",
       " 'mayb',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'meapho',\n",
       " 'mesa',\n",
       " 'met',\n",
       " 'mid',\n",
       " 'might',\n",
       " 'mind',\n",
       " 'mine',\n",
       " 'miss',\n",
       " 'mistak',\n",
       " 'mistress',\n",
       " 'mix',\n",
       " 'money',\n",
       " 'moon',\n",
       " 'morn',\n",
       " 'mother',\n",
       " 'move',\n",
       " 'much',\n",
       " 'music',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'nativ',\n",
       " 'naysay',\n",
       " 'near',\n",
       " 'neck',\n",
       " 'need',\n",
       " 'neighborhood',\n",
       " 'nerv',\n",
       " 'nervou',\n",
       " 'never',\n",
       " 'new',\n",
       " 'next',\n",
       " 'night',\n",
       " 'no',\n",
       " 'northern',\n",
       " 'noth',\n",
       " 'notic',\n",
       " 'now',\n",
       " 'nuclear',\n",
       " 'numb',\n",
       " 'obnoxi',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'on',\n",
       " 'one',\n",
       " 'ooh',\n",
       " 'open',\n",
       " 'out',\n",
       " 'outsid',\n",
       " 'overlap',\n",
       " 'own',\n",
       " 'oww',\n",
       " 'paint',\n",
       " 'paradis',\n",
       " 'park',\n",
       " 'part',\n",
       " 'pas',\n",
       " 'past',\n",
       " 'pawn',\n",
       " 'pay',\n",
       " 'pebbl',\n",
       " 'peopl',\n",
       " 'person',\n",
       " 'phoenix',\n",
       " 'phone',\n",
       " 'pick',\n",
       " 'place',\n",
       " 'plan',\n",
       " 'plant',\n",
       " 'play',\n",
       " 'point',\n",
       " 'post',\n",
       " 'pretend',\n",
       " 'processed_text',\n",
       " 'promanad',\n",
       " 'promis',\n",
       " 'puddl',\n",
       " 'push',\n",
       " 'quit',\n",
       " 'rain',\n",
       " 'rais',\n",
       " 'random',\n",
       " 'rash',\n",
       " 'razor',\n",
       " 'read',\n",
       " 'readi',\n",
       " 'real',\n",
       " 'realli',\n",
       " 'rebellion',\n",
       " 'red',\n",
       " 'regga',\n",
       " 'regret',\n",
       " 'regul',\n",
       " 'reindeer',\n",
       " 'rememb',\n",
       " 'renegad',\n",
       " 'requir',\n",
       " 'reserv',\n",
       " 'respect',\n",
       " 'reveal',\n",
       " 'revolv',\n",
       " 'ride',\n",
       " 'right',\n",
       " 'rim',\n",
       " 'ring',\n",
       " 'rise',\n",
       " 'road',\n",
       " 'roadsid',\n",
       " 'role',\n",
       " 'room',\n",
       " 'root',\n",
       " 'rough',\n",
       " 'ruin',\n",
       " 'rule',\n",
       " 'run',\n",
       " 'sad',\n",
       " 'safe',\n",
       " 'said',\n",
       " 'same',\n",
       " 'sand',\n",
       " 'save',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'scare',\n",
       " 'scold',\n",
       " 'search',\n",
       " 'seasid',\n",
       " 'secret',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'session',\n",
       " 'set',\n",
       " 'shade',\n",
       " 'share',\n",
       " 'she',\n",
       " 'sheep',\n",
       " 'shine',\n",
       " 'shoe',\n",
       " 'shooter',\n",
       " 'shop',\n",
       " 'show',\n",
       " 'shred',\n",
       " 'shuffl',\n",
       " 'sick',\n",
       " 'side',\n",
       " 'sight',\n",
       " 'sign',\n",
       " 'silent',\n",
       " 'sinc',\n",
       " 'skate',\n",
       " 'sky',\n",
       " 'sleaz',\n",
       " 'slip',\n",
       " 'slippin',\n",
       " 'slow',\n",
       " 'slowli',\n",
       " 'small',\n",
       " 'smoke',\n",
       " 'so',\n",
       " 'societi',\n",
       " 'some',\n",
       " 'someon',\n",
       " 'someth',\n",
       " 'sometim',\n",
       " 'song',\n",
       " 'speed',\n",
       " 'spend',\n",
       " 'spent',\n",
       " 'spill',\n",
       " 'stain',\n",
       " 'stake',\n",
       " 'stand',\n",
       " 'star',\n",
       " 'stay',\n",
       " 'step',\n",
       " 'still',\n",
       " 'stolen',\n",
       " 'stone',\n",
       " 'strang',\n",
       " 'street',\n",
       " 'stronger',\n",
       " 'stuck',\n",
       " 'stumbl',\n",
       " 'stun',\n",
       " 'style',\n",
       " 'suckin',\n",
       " 'summer',\n",
       " 'sun',\n",
       " 'sunday',\n",
       " 'suppos',\n",
       " 'sure',\n",
       " 'take',\n",
       " 'talk',\n",
       " 'tall',\n",
       " 'tangl',\n",
       " 'target',\n",
       " 'tea',\n",
       " 'tell',\n",
       " 'temper',\n",
       " 'tend',\n",
       " 'that',\n",
       " 'thatl',\n",
       " 'the',\n",
       " 'them',\n",
       " 'themselv',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'theyr',\n",
       " 'thi',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'those',\n",
       " 'thought',\n",
       " 'three',\n",
       " 'throat',\n",
       " 'tie',\n",
       " 'till',\n",
       " 'time',\n",
       " 'tire',\n",
       " 'to',\n",
       " 'tobe',\n",
       " 'today',\n",
       " 'togeth',\n",
       " 'too',\n",
       " 'top',\n",
       " 'tough',\n",
       " 'town',\n",
       " 'tragedi',\n",
       " 'trailer',\n",
       " 'trash',\n",
       " 'tray',\n",
       " 'treat',\n",
       " 'tree',\n",
       " 'tri',\n",
       " 'trudg',\n",
       " 'truli',\n",
       " 'trust',\n",
       " 'truth',\n",
       " 'tucson',\n",
       " 'tumblewe',\n",
       " 'turn',\n",
       " 'uncomfort',\n",
       " 'unfold',\n",
       " 'unmark',\n",
       " 'unweav',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'use',\n",
       " 'van',\n",
       " 'veem',\n",
       " 'vers',\n",
       " 'voic',\n",
       " 'wa',\n",
       " 'wait',\n",
       " 'wake',\n",
       " 'wanna',\n",
       " 'want',\n",
       " 'watch',\n",
       " 'way',\n",
       " 'we',\n",
       " 'weakest',\n",
       " 'web',\n",
       " 'wed',\n",
       " 'well',\n",
       " 'were',\n",
       " 'western',\n",
       " 'wet',\n",
       " 'weve',\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'whi',\n",
       " 'which',\n",
       " 'white',\n",
       " 'who',\n",
       " 'whole',\n",
       " 'wick',\n",
       " 'wild',\n",
       " 'will',\n",
       " 'win',\n",
       " 'winter',\n",
       " 'wish',\n",
       " 'with',\n",
       " 'without',\n",
       " 'woman',\n",
       " 'word',\n",
       " 'world',\n",
       " 'would',\n",
       " 'wrap',\n",
       " 'wreck',\n",
       " 'write',\n",
       " 'wrong',\n",
       " 'wrote',\n",
       " 'yeah',\n",
       " 'yearsbut',\n",
       " 'yet',\n",
       " 'yo',\n",
       " 'you',\n",
       " 'youll',\n",
       " 'your',\n",
       " 'youv',\n",
       " 'yyour']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = count_vectorizer.get_feature_names()\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(matrix, tokens):\n",
    "\n",
    "    doc_names = [f'song_{i+1}' for i, _ in enumerate(matrix)]\n",
    "    df2 = pd.DataFrame(data=matrix, index=doc_names, columns=tokens)\n",
    "    return(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>118</th>\n",
       "      <th>12</th>\n",
       "      <th>131</th>\n",
       "      <th>195</th>\n",
       "      <th>24</th>\n",
       "      <th>339</th>\n",
       "      <th>367</th>\n",
       "      <th>373</th>\n",
       "      <th>551</th>\n",
       "      <th>599</th>\n",
       "      <th>...</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yearsbut</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>youll</th>\n",
       "      <th>your</th>\n",
       "      <th>youv</th>\n",
       "      <th>yyour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>song_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song_2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 634 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        118  12  131  195  24  339  367  373  551  599  ...  wrote  yeah  \\\n",
       "song_1    0   0    0    0   0    0    0    0    0    0  ...      0     0   \n",
       "song_2    1   1    1    1   1    1    1    1    1    1  ...      1     1   \n",
       "\n",
       "        yearsbut  yet  yo  you  youll  your  youv  yyour  \n",
       "song_1         0    0   0    0      0     0     0      0  \n",
       "song_2         1    1   1    5      1     1     1      1  \n",
       "\n",
       "[2 rows x 634 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_dataframe(vector_matrix.toarray(),tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song-1</th>\n",
       "      <th>testString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>song_1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song_2</th>\n",
       "      <td>0.076705</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          song-1  testString\n",
       "song_1  1.000000    0.076705\n",
       "song_2  0.076705    1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity_matrix = cosine_similarity(vector_matrix)\n",
    "\n",
    "\n",
    "create_dataframe(cosine_similarity_matrix, [\"song-1\",\"testString\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pca\\Desktop\\capstone\\.venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>118</th>\n",
       "      <th>12</th>\n",
       "      <th>131</th>\n",
       "      <th>195</th>\n",
       "      <th>24</th>\n",
       "      <th>339</th>\n",
       "      <th>367</th>\n",
       "      <th>373</th>\n",
       "      <th>551</th>\n",
       "      <th>599</th>\n",
       "      <th>...</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>yearsbut</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>youll</th>\n",
       "      <th>your</th>\n",
       "      <th>youv</th>\n",
       "      <th>yyour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>song_1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song_2</th>\n",
       "      <td>0.038922</td>\n",
       "      <td>0.038922</td>\n",
       "      <td>0.038922</td>\n",
       "      <td>0.038922</td>\n",
       "      <td>0.038922</td>\n",
       "      <td>0.038922</td>\n",
       "      <td>0.038922</td>\n",
       "      <td>0.038922</td>\n",
       "      <td>0.038922</td>\n",
       "      <td>0.038922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038922</td>\n",
       "      <td>0.038922</td>\n",
       "      <td>0.038922</td>\n",
       "      <td>0.038922</td>\n",
       "      <td>0.038922</td>\n",
       "      <td>0.19461</td>\n",
       "      <td>0.038922</td>\n",
       "      <td>0.038922</td>\n",
       "      <td>0.038922</td>\n",
       "      <td>0.038922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 634 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             118        12       131       195        24       339       367  \\\n",
       "song_1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "song_2  0.038922  0.038922  0.038922  0.038922  0.038922  0.038922  0.038922   \n",
       "\n",
       "             373       551       599  ...     wrote      yeah  yearsbut  \\\n",
       "song_1  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "song_2  0.038922  0.038922  0.038922  ...  0.038922  0.038922  0.038922   \n",
       "\n",
       "             yet        yo      you     youll      your      youv     yyour  \n",
       "song_1  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  \n",
       "song_2  0.038922  0.038922  0.19461  0.038922  0.038922  0.038922  0.038922  \n",
       "\n",
       "[2 rows x 634 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "Tfidf_vect = TfidfVectorizer()\n",
    "vector_matrix = Tfidf_vect.fit_transform(data)\n",
    "\n",
    "tokens = Tfidf_vect.get_feature_names()\n",
    "create_dataframe(vector_matrix.toarray(),tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song-1</th>\n",
       "      <th>testString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>song_1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song_2</th>\n",
       "      <td>0.042935</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          song-1  testString\n",
       "song_1  1.000000    0.042935\n",
       "song_2  0.042935    1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_matrix = cosine_similarity(vector_matrix)\n",
    "create_dataframe(cosine_similarity_matrix,[\"song-1\",\"testString\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.042935058593186054"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score = cosine_similarity_matrix[1,0]\n",
    "similarity_score"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff1de33649510ac30c93f6edf1fdd6efd6fa4433b0a5d3feb7f2587c455ddc0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
